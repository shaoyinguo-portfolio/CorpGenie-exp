{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1IvdcVa8k0vsqODVEN2c7pgjxwA4O-BoH",
      "authorship_tag": "ABX9TyMn5qIjy3PFQLI8nzvmnthV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaoyinguo-portfolio/CorpGenie-exp/blob/main/MeetingTranscripting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio File Download"
      ],
      "metadata": {
        "id": "FPFsh5EOT4dp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TVykwjbUCPTp"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab import drive\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "# from google.colab.patches import cv2_imshow\n",
        "from tqdm.notebook import tqdm\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from pathlib import Path\n",
        "from time import time\n",
        "\n",
        "try:\n",
        "    import gdown\n",
        "except:\n",
        "    !pip install gdown\n",
        "    import gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    data_path = Path('/content/drive/MyDrive/Colab Notebooks/data')\n",
        "    print('Mounted Google Drive')\n",
        "except:\n",
        "    data_path = Path('./data')\n",
        "    print('Mounted local drive')\n",
        "\n",
        "if not data_path.exists():\n",
        "    data_path.mkdir()\n",
        "\n",
        "VIDEO_PATH = f'{data_path}/video.data'\n",
        "AUDIO_PATH = f'{data_path}/audio.data'\n",
        "TRANSCRIPT_PATH = f'{data_path}/transcripts.txt'\n",
        "KEYFRAME_PATH = f'{data_path}/key_frames'\n",
        "\n",
        "# gdown.download(url='https://drive.google.com/uc?id=1XfDxDUFQ2bSOCO0DzQtyH2Yzg9Ff0S-F', output=VIDEO_PATH, quiet=False)\n",
        "gdown.download(url='https://drive.google.com/uc?id=1EhqRX_hnPeyc13Zimh11gdUnUIyCEhN6', output=AUDIO_PATH, quiet=False)"
      ],
      "metadata": {
        "id": "lfDu563zHuj9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "83862aff-2fa4-402f-a332-aa9217d2f1cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mounted Google Drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EhqRX_hnPeyc13Zimh11gdUnUIyCEhN6\n",
            "To: /content/drive/MyDrive/Colab Notebooks/data/audio.data\n",
            "100%|██████████| 22.2M/22.2M [00:02<00:00, 11.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/data/audio.data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcript using OpenAI Whisper Locally\n",
        "\n",
        "- Use T4 GPU to accelerate\n",
        "- One might see that Whisper may capture a lot of terminologies wrong. But with the key frames and more powerful LLMs, they will be corrected."
      ],
      "metadata": {
        "id": "xktxurAgT-My"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import whisper\n",
        "except:\n",
        "    !pip install -q openai-whisper\n",
        "    import whisper\n"
      ],
      "metadata": {
        "id": "ICNk6Xe4UX7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff8d343-958f-4a70-8b13-86cd69bd2435"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transcript_audio(audio_path, transcript_path):\n",
        "    all_lines = []\n",
        "\n",
        "    # Change this to 'base' if 'small' causes memory issues,\n",
        "    # but 'small' is generally recommended for Colab balance.\n",
        "    t = time()\n",
        "    model = whisper.load_model(\"small.en\")\n",
        "    print(f\"Whisper model is loaded onto device: {model.device}. Start transcripting...\")\n",
        "    result = model.transcribe(audio_path, word_timestamps=True)\n",
        "\n",
        "    # print(f\"\\nTranscripting complete. Took {int(time() - t)} seconds. Writing to file...\")\n",
        "    # Open a file and write the results line by line\n",
        "    with open(transcript_path, \"w\") as f:\n",
        "        # f.write(f\"Transcription of '{audio_path}' using '{transcript_path}' model:\\n\\n\")\n",
        "\n",
        "        for segment in result['segments']:\n",
        "            # Format the line as [start_time -> end_time] Text\n",
        "            output_line = f\"[{segment['start']:.2f}] {segment['text'].strip()}\\n\"\n",
        "            all_lines.append((float(segment['start']), segment['text'].strip()))\n",
        "            # print(output_line.strip()) # Print to console\n",
        "            f.write(output_line)      # Write to file\n",
        "\n",
        "    print(f\"\\nSaving complete. Took {int(time() - t)} seconds.\")\n",
        "\n",
        "    return all_lines"
      ],
      "metadata": {
        "id": "ChPWYAFtUXzn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_lines = transcript_audio(AUDIO_PATH, TRANSCRIPT_PATH)\n",
        "all_lines[:10]\n"
      ],
      "metadata": {
        "id": "BO2yuxRFUepe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ba0eb1-9e4d-420c-e21a-d77f8cf34f5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:22<00:00, 21.7MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper model is loaded onto device: cpu. Start transcripting...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving complete. Took 4072 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(8.959999999999997,\n",
              "  \"Today, I'm going to talk about TSMC and Intel, COVOS, EMIP, Furbils and Chiplets.\"),\n",
              " (17.54,\n",
              "  'This is part of my class about introduction to packaging process technologies.'),\n",
              " (23.28,\n",
              "  'As you know, TSMC is currently number one in semiconductor manufacturing.'),\n",
              " (31.08,\n",
              "  'Their strength, not just in a high yield of 3 nanometers or even 2 nanometers,'),\n",
              " (38.38,\n",
              "  'their packaging is also not just one of the best, but actually the best.'),\n",
              " (46.62, 'Among the three giants, TSMC, Samsung, and Intel.'),\n",
              " (52.04, 'And their process, of course, is more than COVOS.'),\n",
              " (56.08, 'They have their 3D fabrics and everything else.'),\n",
              " (61.02, \"But today, I'm going to focus pretty much on COVOS only.\"),\n",
              " (64.96, \"And then we'll explore the other arena when ready.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}