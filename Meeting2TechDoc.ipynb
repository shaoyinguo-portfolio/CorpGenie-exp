{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnEv1XV+7sC22xBgwB2xws",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaoyinguo-portfolio/CorpGenie-exp/blob/main/Meeting2TechDoc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demos the tech document generation given key frames and transcripts, using multi-modal models hosted by Open Router.\n",
        "\n",
        "The access tokens are handled by Colab Secret Manager. Please sign up to Open Router and create your own, name it `CorpGenie`"
      ],
      "metadata": {
        "id": "aY_wyr61ZhCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Steps:\n",
        "\n",
        "1. Load key frames and transcript lines, combine and sort by timestamp\n",
        "2. Break into chunks of certain size.\n",
        "3. Recursively feed into LLM with previously generated text"
      ],
      "metadata": {
        "id": "xBSWw5QhEBau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain\n",
        "!pip install -U -q \"langchain[openai]\""
      ],
      "metadata": {
        "id": "RUEYc7ilfPdW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RRPprQRjfzZO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2LCNMG5T8wEr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, userdata\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from time import time\n",
        "from PIL import Image\n",
        "import base64\n",
        "import io\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    import gdown\n",
        "except:\n",
        "    !pip install gdown\n",
        "    import gdown\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "data_path = Path('/content/drive/MyDrive/Colab Notebooks/data')\n",
        "\n",
        "TRANSCRIPT_PATH = f'{data_path}/transcripts.txt'\n",
        "KEYFRAME_PATH = f'{data_path}/key_frames'\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENROUTER_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOuRuM-2AJdb",
        "outputId": "6c70d4f6-2753-4d40-d1b1-a3b11d77c493"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse transcripts text file by timestamps:\n",
        "\n",
        "all_lines = []\n",
        "\n",
        "with open(TRANSCRIPT_PATH, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        # print(line)\n",
        "        splits = line.split(']')\n",
        "        if len(splits) < 2:\n",
        "            continue\n",
        "        ts = float(splits[0].strip().replace('[', ''))\n",
        "        text = splits[1].strip()\n",
        "        all_lines.append((ts, text))\n",
        "\n",
        "print(f'Found {len(all_lines)} lines')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaLZFGK-AwUX",
        "outputId": "0be9fe42-0702-434a-c281-7dc68fd7f2ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 731 lines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load key frame file paths:\n",
        "\n",
        "all_images = []\n",
        "for p in glob.glob('/content/drive/MyDrive/Colab Notebooks/data/key_frames/*.jpg'):\n",
        "    all_images.append((float(Path(p).name.replace('.jpg', '')), p))\n",
        "\n",
        "print(f'Found {len(all_images)} images')\n",
        "# all_images.sort(key=lambda x: x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VM4rMxHA8EA",
        "outputId": "4eda9ef2-5377-4d26-f523-d7b379a1ad16"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 104 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine and sort by timestamps\n",
        "\n",
        "all_events = []\n",
        "for ts, img in all_images:\n",
        "    # Convert numpy array to PIL Image as required by the processor\n",
        "    all_events.append({'timestamp': ts, 'type': 'image', 'data': img})\n",
        "\n",
        "for ts, text in all_lines:\n",
        "    all_events.append({'timestamp': ts, 'type': 'transcript', 'data': text})\n",
        "\n",
        "# Sort events chronologically\n",
        "all_events.sort(key=lambda x: x['timestamp'])"
      ],
      "metadata": {
        "id": "jXDFz0nGBRcr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_image_to_base64(image_path: str, format: str = 'PNG') -> str:\n",
        "    \"\"\"\n",
        "    Reads an image file using PIL, saves it into an in-memory buffer,\n",
        "    and encodes the buffer contents into a Base64 string.\n",
        "\n",
        "    Args:\n",
        "        image_path: The file path to the image.\n",
        "        format: The format to use for the buffer (PNG is recommended for slides).\n",
        "                Must be a format PIL supports.\n",
        "\n",
        "    Returns:\n",
        "        A Base64 encoded string of the image data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Read the image file using PIL\n",
        "        with Image.open(image_path) as img:\n",
        "            # Ensure image is in RGB format if it's grayscale or otherwise different\n",
        "            if img.mode != 'RGB':\n",
        "                img = img.convert('RGB')\n",
        "\n",
        "            # 2. Save the image data to an in-memory buffer (BytesIO)\n",
        "            # This avoids writing a temporary file\n",
        "            buffered = io.BytesIO()\n",
        "            img.save(buffered, format=format)\n",
        "\n",
        "            # 3. Encode the bytes from the buffer to Base64\n",
        "            img_bytes = buffered.getvalue()\n",
        "            img_base64 = base64.b64encode(img_bytes)\n",
        "\n",
        "            # 4. Convert bytes to a string for the API payload\n",
        "            return img_base64.decode('utf-8')\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file was not found at {image_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "3y9NuWrGEm4H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_content_blocks_size(content_blocks):\n",
        "    json_payload_str = json.dumps(content_blocks)\n",
        "    return len(json_payload_str.encode('utf-8'))"
      ],
      "metadata": {
        "id": "5exEMMOdiC6N"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_messages(events, max_size=1e6):\n",
        "    content_blocks = []\n",
        "\n",
        "    for item in events:\n",
        "        time_str = f\"{item['timestamp']:.2f}\" # use seconds for correlation with image names\n",
        "\n",
        "        if item['type'] == 'image':\n",
        "            # only break at images for coherence\n",
        "            if check_content_blocks_size(content_blocks) > max_size:\n",
        "                yield content_blocks\n",
        "                content_blocks = []\n",
        "            base64_image = encode_image_to_base64(item['data'])\n",
        "            content_blocks.append({\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\n",
        "                    \"url\": f\"data:image/png;base64,{base64_image}\"\n",
        "                }\n",
        "            })\n",
        "            content_blocks.append({\n",
        "                \"type\": \"text\",\n",
        "                \"text\": f\"[Timestamp {time_str} s]: Above image is a visual slide content [ImageName: {time_str}] related to the ongoing discussion as follows. Please quote if it adds significant value. Skip if it is not very meaningful.\"\n",
        "            })\n",
        "        elif item['type'] == 'transcript':\n",
        "            content_blocks.append({\n",
        "                \"type\": \"text\",\n",
        "                \"text\": f\"[Timestamp {time_str}]: Transcript excerpt: '{item['data']}'\"\n",
        "            })\n",
        "    yield content_blocks\n"
      ],
      "metadata": {
        "id": "GzQxtF5ZgAuO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    model=\"google/gemini-2.0-flash-001\" # \"google/gemini-2.0-flash-exp:free\"\n",
        ")\n",
        "\n",
        "chain = model | StrOutputParser()\n",
        "\n",
        "system_message = SystemMessage(content=\"\"\"\n",
        "You are a rigorous technical writer assembling a technical document from streamed, timestamped chunks of slides/key frames and transcript captured from a meeting or presentation.\n",
        "Please follow the following steps and rules:\n",
        "1) First correct any miscaptured words in the transcripts by strictly referring to the slides, especially for terminologies and acronyms.\n",
        "2) Write an accurate, detailed, and comprehensive professional technical document, based on the infomation parsed from the meeting key frames and corrected transcripts, together with the text generated in earlier sections as the context (if provided).\n",
        "3) Always cross check all the info especially terminologies, acronyms, and numbers, between key frames, transcripts and previous context.\n",
        "3) Write the new content as a smooth continuation of the previous context (if any) but do not repeat or rewrite the previous context. Skip if it was already mentioned in the previous context.\n",
        "4) Focus on accurate metrics, decisions made and key action items. Record conflicts explicitly if any.\n",
        "5) Never invent metrics, owners, or dates. If unknown, write “TBD”. Do not guess.\n",
        "6）Explicitly quote the names of the key frame in the format of `[ImageName: XXX.XX]` when rewriting based on the transcripts that are discussing the key frame, so that the readers know which frame the ongoing discussion is about.\n",
        "7）Do not quote timestamps.\n",
        "8) Use proper syntax for inline or block fomulas using LaTeX code\n",
        "\"\"\")\n",
        "\n",
        "all_generations = ''\n",
        "total_events = len(all_events)\n",
        "chunk_seperations = []\n",
        "processed_events = 0\n",
        "for i, content_blocks in enumerate(yield_messages(all_events, max_size=5e6)):\n",
        "    processed_events += len(content_blocks)\n",
        "    ts = content_blocks[-1]['text'].split(']')[0] + ']'\n",
        "    if i > 2:\n",
        "        break\n",
        "    human_message = HumanMessage(content=[{\"type\":\"text\", \"text\": f\"---------Previous Context--------\\n{all_generations}\\n---------End of Previous Context--------\\n\"}])\n",
        "    human_message = HumanMessage(content=content_blocks)\n",
        "    all_generations += chain.invoke([system_message, human_message])\n",
        "    print(f'\\nProcessed Chunk #{i+1}, {processed_events} / {total_events} content blocks @ {ts}, Generated {len(all_generations)} Characters')\n",
        "    chunk_seperations.append(len(all_generations))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMyjwRn8oSss",
        "outputId": "e65f1c73-8148-47f0-9954-1a7e14390dfa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed Chunk #1, 210 / 835 content blocks @ [Timestamp 847.34], Generated 4232 Characters\n",
            "\n",
            "Processed Chunk #2, 282 / 835 content blocks @ [Timestamp 1178.70], Generated 5584 Characters\n",
            "\n",
            "Processed Chunk #3, 306 / 835 content blocks @ [Timestamp 1248.28], Generated 7814 Characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, chunk_seperation in enumerate(chunk_seperations):\n",
        "    if i == 0:\n",
        "        print(all_generations[0:chunk_seperation])\n",
        "    else:\n",
        "        print(all_generations[chunk_seperations[i-1]:chunk_seperation])\n",
        "    print(f'\\n\\n--------- Chunk Seperation {i} ---------\\n\\n')"
      ],
      "metadata": {
        "id": "FIxnWA8J9yhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Findings:\n",
        "\n",
        "1. `google/gemini-2.0-flash-001` follows the instruction the best out of similarly priced models (e.g. `openai/gpt-4.1-nano` etc)\n",
        "2. Iteratively evaluate quality of the output and fine tune instuctions\n",
        "3. Removing repetitive key frames due to presenter going back and forth produces greater coherence of the text\n",
        "4. TODOs:\n",
        "    - add redundant key frame removal algorithm into the extraction process, based on `n_frames_to_last_repeat` and/or `time_to_last_repeat` criteria\n",
        "    - Consider adding overlapping content between chunks to enhance continuity\n",
        "    - Try out a final refining step for all concatenated text"
      ],
      "metadata": {
        "id": "T86eOyE-_nHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Output:\n",
        "\n",
        "The presentation focuses on packaging process technologies, particularly those of TSMC and Intel, with an emphasis on CoWoS (Chip-on-Wafer-on-Substrate), EMIB (Embedded Multi-die Interconnect Bridge), Foveros, and chiplets [ImageName: 1.00].  TSMC is recognized as a leader in semiconductor manufacturing, not only for its high yield in advanced nodes like 3nm and 2nm, but also for its packaging technology.  The discussion will primarily focus on CoWoS while acknowledging TSMC's broader 3D fabric capabilities.  Intel's EMIB and Foveros technologies will also be touched upon, along with the challenges and advantages of utilizing chiplets. Before diving into specifics, Key Performance Indicators (KPIs) for packaging technology, often referred to as \"P3C2,\" needs to be clarified.\n",
        "\n",
        "According to Douglas of TSMC, the P3C2 acronym represents Performance, Power, Package Profile, Cycle Time, and Cost [ImageName: 90.00]. Performance considers bandwidth (BW), maximum frequency (Fmax), and overall function. Power relates to efficiency and thermal properties (Tj).  Package profile includes footprint and thickness. Cycle time refers to the speed of bringing the product to market, while cost represents the financial burden on customers.  However, the speaker notes the absence of \"yield and reliability\" in the P3C2 definition, emphasizing their critical importance from an engineering perspective, despite them being often overlooked by customers. Heterogeneous system integration requires continuous pitch scaling, aiming to reduce dimensions from 36 microns to a few microns to pack more components into a single package.\n",
        "\n",
        "TSMC's 3D Fabric technology includes both 3D silicon stacking and advanced packaging solutions [ImageName: 209.00].  Silicon stacking options include SoIC (System on Integrated Chips)-P (Bumped), TSMC-SoIC®, and SoIC-X (Bumpless).  Advanced packaging solutions encompass CoWoS® (including CoWoS-S with a silicon interposer and CoWoS-L/R with an RDL interposer), InFO-PoP, InFO-2.5D, and InFO-3D. The primary focus will be on CoWoS due to its use of a silicon interposer.\n",
        "\n",
        "TSMC's CoWoS updates for 2023 are primarily aimed at High-Performance Computing (HPC) applications that require the integration of advanced logic and High Bandwidth Memory (HBM) [ImageName: 266.00].  TSMC supports over 140 CoWoS products for more than 25 customers. They are developing a 6x reticle-size (approximately 5,000 mm²) RDL interposer capable of accommodating 12 stacks of HBM memory. The AI server market is estimated to reach $1 trillion in the US alone by 2030. High-end customers like Nvidia, AMD, and Qualcomm utilize these advanced packaging solutions. The CoWoS product count is around 140, significantly less compared to Cisco products, which number in the thousands. The 6x reticle size RDL interposers have redistribution layers inside the silicon, which allows signal transmission within the silicon interposer. The previous generation in 2021 used 3x reticle size (~2,500 mm²), and the current generation uses 4x reticle size.\n",
        "\n",
        "The term 'reticle size' refers to the maximum size of a die that a lithography tool can print [ImageName: 553.00]. A standard reticle field is 26mm x 33mm, which equals 858 mm². Most lithography tools, including ASML tools, use this size.  While the lens of the tool might be huge, the mask size used is 4x, where light with a pattern shines through it onto the wafer with a 4x reduction of the 26mm x 33mm size. This is a universal standard, which makes it very difficult to have die sizes larger than this. For high-end applications with extreme ultraviolet (EUV) lithography, printing is done in a specific manner, with the mask orientation at 26x33 at 4x and 8x in the Y-axis. This is because of the difficulty of printing larger dies with only this area. Therefore, to create a larger die, it is printed twice. Intel had the problem with printing twice, so made a larger mask.  The current mask size is 6 inches, and 26x33 for 4x can be amplified using a 6-inch mask.  However, for high-end EUV lithography where printing is done twice, a 9-inch mask is needed, which no one wants to commit to. TSMC is developing a 6x reticle size, which translates to 5,148 mm² (26x33 x 6).\n",
        "\n",
        "\n",
        "\n",
        "--------- Chunk Seperation 0 ---------\n",
        "\n",
        "\n",
        "The NVIDIA H100 is a large GPU with six memory chips [ImageName: 849.00]. The GPU, GH100, has 80 billion transistors. The die size is 814 $mm^2$.\n",
        "The size of the die is limited by manufacturing constraints. NVIDIA uses a TSMC N4 process. The yield is affected by the large die size.\n",
        "\n",
        "The TSMC yield is 80% for Apple A13, which has die size about 1 cm x 1 cm, which is 100 $mm^2$ [ImageName: 936.00]. The yield of TSMC for GH100 (die size > 8 $cm^2$) should drop to around 30-40% for such big GPUs and will stay low. The larger the die, the lower the yield due to Poisson statistics. The yield reduction is a function of area. The presenter generated a formula showing the yield reduction as a function of area:\n",
        "$$y(A) = (1 + \\frac{A * 0.223}{2})^{-2}$$\n",
        "where $y(A)$ is the yield as a function of area $A$.\n",
        "\n",
        "The presenter explained in a video that particle landing on a wafer is like a bomb landing in London in World War II, which follows a Poisson distribution [ImageName: 1001.00]. In the video, the presenter explained that R. Clark divided the London area by the number of grids and calculated probabilities of bombs dropping in each grid.\n",
        "\n",
        "Contaminants and particles landing on a wafer are like German bombs on London from the eyes of statistics [ImageName: 1144.00]. The TSMC 5nm Nvidia yield is 80%. There are many different types of particles.\n",
        "\n",
        "\n",
        "\n",
        "--------- Chunk Seperation 1 ---------\n",
        "\n",
        "\n",
        "The discussion focuses on yield models and surface particles [ImageName: 1182.00], noting that killer-defect density value for Surface Prep is calculated based on Poisson's model for yield = 99%. Values changed from 2004 are small, due to die size changes, 97 (in 2004 ITRS) to 94.2 (in 2005 ITRS) for 2005 critical particle count per wafer. Currently, different models are used for Yield Enhancement and Starting Materials Surface Prep. Final particle density values are approximately the same for all models. YE and FE will have a workshop to determine the appropriate Starting Materials' defect levels and establish specific call outs for critical cleans (specifically pre-gate). Concern is ability to measure defects at critical particle diameter that contributes to yield.\n",
        "\n",
        "It's explained that particles landing on a wafer is also Poisson [ImageName: 1185.00]. In the semiconductor process world, it assumes that \"particles/defects arriving on the wafer\" are like bombs landing in London, a random event with Poisson distribution as follows:\n",
        "\n",
        "$P(k | \\mu) = e^{-\\mu} \\frac{\\mu^k}{k!}$\n",
        "\n",
        "where a simple Yield model is developed assuming no defects before time t\n",
        "\n",
        "$P(k = 0) = e^{-\\mu} = e^{-DA}$\n",
        "\n",
        "where D = defect density, A = critical area.\n",
        "\n",
        "The discussion refers to a classic yield model modified by ITRS [ImageName: 1198.00] with the formula:\n",
        "\n",
        "$Y = f(A, D)$\n",
        "\n",
        "where D = defect density, which has a distribution with respect to the defect size and A = critical area (in which a defect has a high probability of resulting in a fault, which also has a distribution with respect to the defect size).\n",
        "\n",
        "$\\Upsilon = \\int_0^{\\infty} e^{-DA} f(D) dD$\n",
        "$f(D) = \\Gamma(\\alpha) B^{\\alpha} ]^{-1} D^{\\alpha - 1} e^{-D/ \\beta}$\n",
        "\n",
        "Negative binomial:\n",
        "$Y_r = (1 + \\frac{A D}{\\alpha})^{-\\alpha}$\n",
        "\n",
        "An example of TSMC Yield vs Die sizes [ImageName: 1211.00] is discussed. TSMC reported that their yield rate is 80% for Apple A13 (die size 0.44cm * 0.44cm). The question is what happens to yield rate if the die size changes? The answer is that they need to estimate $D_0$ first.\n",
        "\n",
        "$Y(0) \\sim e^{-DA}$\n",
        "$0.8 = exp(-0.44cm * 0.44cm * D_0)$\n",
        "$D_0 =  -ln(0.8) / 0.44^2 = 1.15 / cm^2$\n",
        "\n",
        "ITRS suggests $\\alpha = 2$\n",
        "$\\Upsilon(A) = (1 + \\frac{A*1.15}{2})^{-2}$\n",
        "\n",
        "\n",
        "\n",
        "--------- Chunk Seperation 2 ---------\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CL58_yLN3w6A"
      }
    }
  ]
}